# 1、kibana分析nginx日志，还在纠结用filebeat还是logstash
https://elasticsearch.cn/question/6479

服务器部署在阿里云，ES用的是5.3版本，里面index存了一些信息，然后用django写了个web让用户可以搜索ES里面的数据。

现在想收集nginx的log到kibana进行可视化，主要是想看一下每次访问的ＩＰ地址，对用户的location做一个可视化。

之前看一些ｂｌｏｇ文章，上面说如果用logstash来分析日志，然后在转存到ＥＳ，会有delay，而且web端也在不停的访问ES，

所以怕服务器CPU过载严重，毕竟用的是最普通的服务器。后来看了官方的ＢEATS视频，里面用的filebeat是６.X版的，然后配置的部分没有详细的讲，

所以看的不是特别的明白，想在就向问一下，对于我这种需求，到底用那个比较好呢？而且又不会给服务器带来太大的压力？谢谢了。

【回复】
收集端还是用filebeat比较好，不做日志解析，只要求将日志运出来即可，资源消耗非常低。

如果手里硬件资源不多，可以不用logstash，filebeat直接发到ES集群的ingest node，在ingest node上配置一个grok pipeline负责解析日志就可以了。

查一下官方的文档，重点是理解filebeat的elasticsearch output怎么配置， ES一端的ingest node怎么配置。

# 2、elasticsearch 可以指定不参与搜索的字段么

就是索引映射很复杂，但有些字段是敏感信息，不想被搜索出来，elasticsearch可以控制搜索时不搜索这些字段么

如果你不想该字段被搜索，可以在mapping里面设置index为false。这样es不会在该字段上建立索引，在该字段上搜索就会报错。
```
PUT myindex/
{
  "mappings": {
    "mytype":{
      "properties": {
      "name":{
        "type": "text",
        "index": false
      },
      "title":{
        "type": "text"
      }
    }
    }
    
  }
}
```

# 3、ES图片搜索？

https://elasticsearch.cn/question/6474

可以借助局部敏感 LSH 或者 pHash 来实现

https://stackoverflow.com/questions/32785803/similar-image-search-by-phash-distance-in-elasticsearch

Github 也有一个开源项目使用了多种 Hash 算法借助 ES 来实现图片搜索：

https://github.com/usc-isi-i2/elasticsearch-image-features

https://github.com/lior-k/fast-elasticsearch-vector-scoring

# 4、关于segment.memory的大小？应该如何配置或者限制？

https://elasticsearch.cn/question/6500

segment 的大小，和 indexing buffer 有关，有三种方式会生成 segment，

一种是 indexing buffer 写满了会生成 segment 文件，默认是堆内存的10%，是节点共享的，

一种是 index buffer 有文档，但是还没满，但是 refresh 时间到了，这个时候就会把 buffer 里面的生成 segment 文件，

还有最后一种就是es 自动的会将小的 segment 文件定期合并产生新的 segment 文件。

你此处的2g 大小和 indexbuffer 最直接相关，你可以调整 index buffer 大小来改变。
https://www.elastic.co/guide/en/elasticsearch/reference/6.5/indexing-buffer.html

# 5、es父子文档

查询子文档时候，往往用到has_parent，但是这样会有一个问题，就是查出来都子文档肯定有匹配都父文档，
而实际应用时，可能出现没有对应都父文档，在页面显示的就是不显示对应的信息，es提供这种方式吗

加上一个 innter_hits 条件就会返回对应的父子文档了。
```
GET parent/_search
{
  "query": {
    "has_child": {
      "type": "child",
      "query": {
        "match": {
          "field": "value"
        }
      },
      "inner_hits" : {}
    }
  }
}
```

# 6、ES检索优化问题
查询的索引是car_*, 但是我们的索引是按照天建的, 也就是car_2018_01_01~car_2018_12_05,

 因为要保留1年的数据, 那么一个最简单的查询(最近一小时), 如果我指定car_*索引组, 那么es会不会从
 
 car_2018_01_01~car_2018_12_05的索引全部过一遍, 并且每个index下有6个shard, 这样查询效果就很不理想
 
 【回复】
 要看ES版本的，早期版本即使放了时间这个filter，查询开销依旧很高。 
 比较新的版本（具体哪个版本开始记不清，也许是5.x以后）， 对于时间字段，会在索引里记录该字段的上下边界，
 如果查询的时间范围和他的上下边界没有重叠，就将查询改写为match_non，从而跳过后面的查询过程，速度大大提高。 
 但开销最小的查询方式，还是根据查询时间范围，直接根据索引名称定位出要查询的索引，可以减少很多无谓的磁盘IO。
 
 # 7、ES数据快照到HDFS

1、ES官网提供快照方式和es-hadoop，不知道哪位用过，实现备份用哪种方式比较快速，我自己测试了快照方式，效率不是很快，大概1G/分钟、

2、快照方式，配置了压缩，但是存入hdfs的数据无压缩（比原来还稍微大一下），不知道有没有更好的方式进行压缩存储

【回复】
ES 做快照和使用 es-Hadoop 倒数据是完全的两种不同的方式，使用 ES-Hadoopp 后期导入的成本可能也不小。

如果要恢复快，当然是做快照和还原的方式最快，速度完全取决于网络和磁盘的速度。

如果为了节省磁盘，快照的时候，可以选择6.5最新支持的 ```source_only 模式```，导出的快照要小很多，不过恢复的时候要进行重建，速度慢。

# 8、关于滚动模式，关注terms耗时的化是不是就不需要缩小分片了

按天索引，使用一段时间后发现terms耗时过长，怀疑是因为分片大小波动较大导致的，
所以考虑使用滚动模式控制分片大小。这样是不是只要根据最优的文档数创建分片，然后做迁移就好了？
缩小分片会不会对查询优化基本无用？

【回复】
能测出分片的最佳大小用 Rollover 最合适了，数据不写了，可以 force merge 一下，可以提升查询性能。

如果分片还能缩小那你的前提就不存在了。

# 9、ES 6.4 Xpack 安全模式下，Transprot连接客户端，SSL加密认证必须双向认证？

不能关闭server对client的认证吗，和http一样单向认证？

【回复】

必须启用，不然不安全的。没有 SSL 加密，你就算设置了密码，也是在裸奔。

# 10、es update字段时，如何将数值再除以2 ？

在es里面 update字段时如何把数值再除以2 ？
就 像sql 语句 update user set age= age / 2   where id=02  这样的，在es里面如何实现 ？
 
 
这是我更新时的指令：
```
GET user/doc/02/_update
{
    "doc" : {
        "age" : "38" 
    },
    "doc_as_upsert" : true
}
```
【回复】

age  不改成数字类型，效率比较低。不过也可以写，如下：
```
PUT user/doc/02
{
        "age" : "38" 
}
    
POST user/doc/02/_update
{
    "script" : {
        "source": """
        ctx._source.age = (Float.parseFloat(ctx._source.age)/params.count).toString();
        """,
        "lang": "painless",
        "params" : {
            "count" : 2
        }
    }
}

GET user/doc/02  

```

# 11、【重要】Shard大小官方推荐值为20-40GB, 具体原理呢？

https://elasticsearch.cn/question/6544

As titled, Shard大小超过40GB后，读写速度迅速下降，具体是什么原因导致呢？

Lucene 底层没有这个大小的限制，20-40GB 的这个区间范围本身就比较大，经验值有时候就是拍脑袋，不一定都好使。
 
Elasticsearch 对数据的隔离和迁移是以分片为单位进行的，分片太大，会加大迁移成本。

一个分片就是一个 Lucene 的库，一个 Lucene 目录里面包含很多 Segment，
每个 Segment 有文档数的上限，Segment 内部的文档 ID 目前使用的是 Java 的整型，也就是 2 的 31 次方，
所以能够表示的总的文档数为Integer.MAX_VALUE - 128 = 2^31 - 128 = 2147483647 - 1 = 2,147,483,519，也就是21.4亿条。

同样，如果你不 force merge 成一个 Segment，单个 shard 的文档数能超过这个数。
单个 Lucene 越大，索引会越大，查询的操作成本自然要越高，IO 压力越大，自然会影响查询体验。
具体一个分片多少数据合适，还是需要结合实际的业务数据和实际的查询来进行测试以进行评估。

# 12、随机函数用完需要删除seed的字符串嘛？怎么删除？

ScoreFunctionBuilders.randomFunction().seed("1") 
使用大量不同得seed之后我需要删除seed值嘛？有些seed过期之后就再也不会用了，怕浪费内存

【回复】：
不需要删除
设置 seed 其实就是设置 RandomScoreFunctionBuilder 中一个属性，
当你这个 builder 被回收的时候，自然 seed 也就被回收了，不会耗费内存

# 13、目前beats工具只有官网列出来的8种吗？

https://www.elastic.co/guide/en/beats/libbeat/6.5/community-beats.html

除了官方的，请看这个页面，非常多，几十个了：

# 14、如何选择在ES之前处理写入的中间件？

场景：ES是用来存业务数据，把ES作为数据存储的平台，提供查询服务
数据写入方式包括，应用调用HTTP接口写入，通过Hive的外表导入到ES
 
问题：上述两种方式由于都存在请求流程不可控的情况，希望能在ES前面加一层MQ，比如kafka，来缓解写入的压力
根据这个需求，就需要选择一款可以将  ES和kafka结合起来，并且还能处理现有的 hive等场景的数据写入，要选择什么样的中间件产品能满足上述需求呢？
 
还请有经验的大神指教。

【参考思路】我们目前的做法是：
1. 做个平台给各个有读写需求的部门自己设置自己的mapping，比如字段类型、是否按天、月、年建索引…
2. 开一个（如果有特殊需求可能是好几个）Kafka的topic
3. 约定好交互格式，（比如，用 index|type|_id|timestamp|randomkey 作为kfk的key），然后（用docker技术）动态增减consumer做数据的导入
 
由于公司技术栈主要是Java，所以几个组件，包括数据预处理的插件都是Java实现的，也可以选择包括golang、python、ruby…等各种不同的实现。不知道能不能解决你的问题？

# 15、ES的父子查询中如何使用scripts的来过滤数据

【转换思路】不一定需要脚本来过滤，对子文档的过滤可以使用 inner hits
可以参考官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-inner-hits.html

# 16、什么我们集群大量写入的时候，load负载及其不均匀呀？

你去调用下 hot_threads 看它在干嘛？此时 cpu 利用率看起来是不高的，那是不是这个节点的磁盘 IO 性能有问题？

# 17、elasticsearch 宕机1台 会有20分钟不可访问


向各位请教一下，我们有9台物理机，27个节点的es服务器，总数据量大于10来个T，每天数据大概1个T，当有1台物理机宕机的情况下，
集群是黄色，但是会有20来分钟，运行非常慢，请求会超时。 我理解，当时集群会做两个动作，1个是副本的恢复，1个是数据的重平衡，
有什么办法解决这个问题吗？能不能调整他降低他恢复的速度？不要1台宕机就影响一段时间数据无法查询和写入


【回复1】

如集群正常工作的情况下，cpu/磁盘io已经接近饱和了，那么数据恢复的确可能影响到读写的吞吐量，这个时候只能是控制recovery的速率（集群有个设置indices.recovery.max_bytes_per_sec) 或者按照Rockybean的方法，延缓recovery触发的时机，等待故障节点恢复重新加入集群以后，从本地恢复大部分数据，尽量减小recovery带来的影响。 如果这些都不解决问题，就只能是扩容硬件了。
 
不过你有10台物理机，数据总量只有10TB左右，一台机器跑一个ES实例性能会更好。 

多实例部署，如果heap划分又很大，通常会造成heap空间过剩而系统缓存不够的尴尬情况，性能相反会大幅降低。一般来说跑多实例的目的是为了在一个节点上存储尽量多的数据，响应的代价是牺牲一些读写性能。
 
最后一点就是要注意控制集群的index/shard的数量，如果shard数量非常多（上万），出现节点故障的情况下，master节点可能会不堪重负。

如果你没有单独设立master，而是混入了data node，那么也是有可能对读写产生较大的影响。

【回复2】
你现在1台物理机有3个节点，所以实际是一次3个 es 节点挂了，那么实际需要重新分配1TB 左右的数据，这个过程是会影响集群性能的。
有一个解决方法是延迟集群再分配分片的时间，在这个时间到来之前将停掉的节点启动起来，可以节省大量分片重分配的时间。
https://www.elastic.co/guide/en/elasticsearch/reference/current/delayed-allocation.html
 
PUT _all/_settings
{
  "settings": {
    "index.unassigned.node_left.delayed_timeout": "5m"
  }
}
这个值你可以设的大一些，比如一天 1d，这样有充分的时间来恢复节点


# 18、bulk提交后无响应

【回复】 ```bulk推荐的大小为 5-10M```，你这个文件确实太大了；
处理速度还与你的 mapping 映射有直接关系；
如果某个字段内容特别多，又被索引，那么将会耗费大量时间在分词上；
 
对于 bulk 操作，你可以通过查看 task 相关的 API，来查看任务状态
